{"title":"Raft算法基础介绍","date":"2024-04-03T13:33:09.000Z","toc":true,"source":"_posts/2024-04-03-Raft算法基础介绍.md","raw":"---\ntitle: Raft算法基础介绍\ndate: 2024-04-03 21:33:09\ntags: [技术基础, 分布式架构]\ntoc: true\n---\n\nRaft 算法是一种管理复制日志的一致性算法，主要分成四个部分，领导选取，日志复制，安全和成员变化。\n\n简单来说，Raft 就是在集群中选举一个领导者，客户端写操作直接写给领导者，领导者更新本地日志，并将日志复制到其他节点。大多数节点返回处理成功之后，领导就返回客户端更新成功，并下发更新命令，让大多数节点更新数据。\n\nRaft 算法被广泛应用于集群同步之中，例如 Redis 哨兵集群的选举等。本文是对 Raft 算法基本内容的简单介绍，不涉及具体的算法实现和细节。\n\n如果想要更直观、详细地了解 Raft 算法，推荐通过 [Raft 动画](https://thesecretlivesofdata.com/raft/)网站来更直观地了解 Raft 算法的基本流程，以及阅读 [Raft 论文译文](https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md)来获取更加详细的信息。\n\n## 领导选取\n\nRaft 的节点有三种状态：跟随者，候选人和领导者。\n\n一开始，每个节点都是跟随者，经过领导选举的流程，会产生一个领导者。在正常情况下，一个集群只有一个领导者，负责接收客户端消息以及日志同步，剩下的都是跟随者。\n\n当跟随者有一个选举时间没有收到来自领导者的消息后，就会把自己变成候选人，并给自己投票。这里还会额外记录这是第几次选举，也就是任期号。\n\n节点变成候选人之后，会给其他的机器发送竞选通知。在此期间，候选人节点会一直保持候选人状态，直到以下三种情况发生：\n\n- 候选人赢得选举成为领导者\n\n其他节点收到竞选通知之后，按照先来先服务的原则，如果自己还没有变成候选人且没有给其他的候选人节点投票过，就会投票给该候选人节点。如果该候选人节点得到了大多数的选票，就会变成领导者。\n\n- 其他候选人赢得选举成为领导者\n\n其他节点收到竞选通知之后，已经给其他的候选人节点投票了，就会忽视该候选人节点的通知。如果其他候选人节点得到了大多数的选票，那个候选人节点就会成为领导者，开始发送领导者同步消息。\n\n该候选人节点收到领导者同步消息，并且判断是当前或者更晚的任期选举出来的领导者，就知道已经有了其他的领导者，自动退出候选人状态成为跟随者。\n\n- 一段时间之后没有选出领导者\n\n这种情况一般出现在好几个候选人的情况下，导致所有候选人都没有得到大部分选票。在这种情况下，每一个候选人都会选举超时，之后会依据随机的选举超时时间，再次重复领导选举过程。由于随机的选举超时时间，下一轮选举中候选人出现的时间会有差别，这让这种情况很少发生。\n\n## 日志复制\n\n领导者会按照一个时间定时给其他的机器发送心跳请求，其他机器收到后也会回复。这个时间需要远小于选举超时时间，避免在领导者正常工作的情况下，因为网络延迟等原因让跟随者收不到领导者的消息，错误认为当前集群没有领导者。\n\n当客户端请求的时候，领导者先更新自己本地的日志，然后把日志通过心跳请求复制给其他的机器，其他机器更新本地日志后，会在回复心跳的时候通知领导者。这里如果有机器没有回包，领导人即使向客户端回包了，也会无限重试，直到所有的跟随者都存储了日志。\n\n领导者收到大多数机器的更新之后，就会执行日志更新本地数据，通知客户端请求成功。下一次心跳，领导者会把 commit 请求发给其他机器。其他机器收到后，也会更新自己的本地数据。\n\n## 安全性\n\n### 选举限制\n\n选举的时候会保证领导者一定有所有的日志。投票请求会包含当前机器最新的日志，如果跟随者发现候选人发来的投票请求中，日志没有自己新，那就会拒绝投票。\n\n基于这个原理，可以证明领导者一定拥有之前提交的日志信息。简单来说就是大多数机器都复制了才会提交，而提交之后大多数机器都有最新的日志，不会投票给没有日志的候选人。\n\n另外，服务器有当前领导者存在的时候，不会响应要求投票的请求，这保证了旧配置服务器被移除的时候它可能会进行选举过程的问题。\n\n### 避免脑裂\n\n如果网络之间出现问题，例如 5 台机器，2 台机器和其他 3 台机器不通。\n\n这种情况下，这个集群会出现两个领导者。其中一个是原本的领导者，位于 2 台机器的集群；另一个是 3 台机器的集群新选举出来的。但是 2 台机器的小集群因为得不到大多数机器的更新确认信息，所以无法更新数据，而 3 台机器的集群则可以更新。\n\n当网络恢复后，2 台机器的集群收到 3 台机器集群的心跳请求，因为 3 台机器的集群的任期号更高，所以会采用 3 台机器集群的日志和数据，保证了集群整体还是一致的。\n\n## 参考资料\n\n- [Raft 动画](https://thesecretlivesofdata.com/raft/)\n- [Raft 论文译文](https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md)\n","slug":"Raft算法基础介绍","published":true,"updated":"2024-04-28T08:14:46.218Z","_id":"clvj9j4fd0005r4w9eqw8fth5","comments":true,"layout":"post","photos":[],"html":"<p>Raft 算法是一种管理复制日志的一致性算法，主要分成四个部分，领导选取，日志复制，安全和成员变化。</p>\n<p>简单来说，Raft 就是在集群中选举一个领导者，客户端写操作直接写给领导者，领导者更新本地日志，并将日志复制到其他节点。大多数节点返回处理成功之后，领导就返回客户端更新成功，并下发更新命令，让大多数节点更新数据。</p>\n<p>Raft 算法被广泛应用于集群同步之中，例如 Redis 哨兵集群的选举等。本文是对 Raft 算法基本内容的简单介绍，不涉及具体的算法实现和细节。</p>\n<p>如果想要更直观、详细地了解 Raft 算法，推荐通过 <a href=\"https://thesecretlivesofdata.com/raft/\">Raft 动画</a>网站来更直观地了解 Raft 算法的基本流程，以及阅读 <a href=\"https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md\">Raft 论文译文</a>来获取更加详细的信息。</p>\n<h2 id=\"领导选取\"><a href=\"#领导选取\" class=\"headerlink\" title=\"领导选取\"></a>领导选取</h2><p>Raft 的节点有三种状态：跟随者，候选人和领导者。</p>\n<p>一开始，每个节点都是跟随者，经过领导选举的流程，会产生一个领导者。在正常情况下，一个集群只有一个领导者，负责接收客户端消息以及日志同步，剩下的都是跟随者。</p>\n<p>当跟随者有一个选举时间没有收到来自领导者的消息后，就会把自己变成候选人，并给自己投票。这里还会额外记录这是第几次选举，也就是任期号。</p>\n<p>节点变成候选人之后，会给其他的机器发送竞选通知。在此期间，候选人节点会一直保持候选人状态，直到以下三种情况发生：</p>\n<ul>\n<li>候选人赢得选举成为领导者</li>\n</ul>\n<p>其他节点收到竞选通知之后，按照先来先服务的原则，如果自己还没有变成候选人且没有给其他的候选人节点投票过，就会投票给该候选人节点。如果该候选人节点得到了大多数的选票，就会变成领导者。</p>\n<ul>\n<li>其他候选人赢得选举成为领导者</li>\n</ul>\n<p>其他节点收到竞选通知之后，已经给其他的候选人节点投票了，就会忽视该候选人节点的通知。如果其他候选人节点得到了大多数的选票，那个候选人节点就会成为领导者，开始发送领导者同步消息。</p>\n<p>该候选人节点收到领导者同步消息，并且判断是当前或者更晚的任期选举出来的领导者，就知道已经有了其他的领导者，自动退出候选人状态成为跟随者。</p>\n<ul>\n<li>一段时间之后没有选出领导者</li>\n</ul>\n<p>这种情况一般出现在好几个候选人的情况下，导致所有候选人都没有得到大部分选票。在这种情况下，每一个候选人都会选举超时，之后会依据随机的选举超时时间，再次重复领导选举过程。由于随机的选举超时时间，下一轮选举中候选人出现的时间会有差别，这让这种情况很少发生。</p>\n<h2 id=\"日志复制\"><a href=\"#日志复制\" class=\"headerlink\" title=\"日志复制\"></a>日志复制</h2><p>领导者会按照一个时间定时给其他的机器发送心跳请求，其他机器收到后也会回复。这个时间需要远小于选举超时时间，避免在领导者正常工作的情况下，因为网络延迟等原因让跟随者收不到领导者的消息，错误认为当前集群没有领导者。</p>\n<p>当客户端请求的时候，领导者先更新自己本地的日志，然后把日志通过心跳请求复制给其他的机器，其他机器更新本地日志后，会在回复心跳的时候通知领导者。这里如果有机器没有回包，领导人即使向客户端回包了，也会无限重试，直到所有的跟随者都存储了日志。</p>\n<p>领导者收到大多数机器的更新之后，就会执行日志更新本地数据，通知客户端请求成功。下一次心跳，领导者会把 commit 请求发给其他机器。其他机器收到后，也会更新自己的本地数据。</p>\n<h2 id=\"安全性\"><a href=\"#安全性\" class=\"headerlink\" title=\"安全性\"></a>安全性</h2><h3 id=\"选举限制\"><a href=\"#选举限制\" class=\"headerlink\" title=\"选举限制\"></a>选举限制</h3><p>选举的时候会保证领导者一定有所有的日志。投票请求会包含当前机器最新的日志，如果跟随者发现候选人发来的投票请求中，日志没有自己新，那就会拒绝投票。</p>\n<p>基于这个原理，可以证明领导者一定拥有之前提交的日志信息。简单来说就是大多数机器都复制了才会提交，而提交之后大多数机器都有最新的日志，不会投票给没有日志的候选人。</p>\n<p>另外，服务器有当前领导者存在的时候，不会响应要求投票的请求，这保证了旧配置服务器被移除的时候它可能会进行选举过程的问题。</p>\n<h3 id=\"避免脑裂\"><a href=\"#避免脑裂\" class=\"headerlink\" title=\"避免脑裂\"></a>避免脑裂</h3><p>如果网络之间出现问题，例如 5 台机器，2 台机器和其他 3 台机器不通。</p>\n<p>这种情况下，这个集群会出现两个领导者。其中一个是原本的领导者，位于 2 台机器的集群；另一个是 3 台机器的集群新选举出来的。但是 2 台机器的小集群因为得不到大多数机器的更新确认信息，所以无法更新数据，而 3 台机器的集群则可以更新。</p>\n<p>当网络恢复后，2 台机器的集群收到 3 台机器集群的心跳请求，因为 3 台机器的集群的任期号更高，所以会采用 3 台机器集群的日志和数据，保证了集群整体还是一致的。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li><a href=\"https://thesecretlivesofdata.com/raft/\">Raft 动画</a></li>\n<li><a href=\"https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md\">Raft 论文译文</a></li>\n</ul>\n","excerpt":"","more":"<p>Raft 算法是一种管理复制日志的一致性算法，主要分成四个部分，领导选取，日志复制，安全和成员变化。</p>\n<p>简单来说，Raft 就是在集群中选举一个领导者，客户端写操作直接写给领导者，领导者更新本地日志，并将日志复制到其他节点。大多数节点返回处理成功之后，领导就返回客户端更新成功，并下发更新命令，让大多数节点更新数据。</p>\n<p>Raft 算法被广泛应用于集群同步之中，例如 Redis 哨兵集群的选举等。本文是对 Raft 算法基本内容的简单介绍，不涉及具体的算法实现和细节。</p>\n<p>如果想要更直观、详细地了解 Raft 算法，推荐通过 <a href=\"https://thesecretlivesofdata.com/raft/\">Raft 动画</a>网站来更直观地了解 Raft 算法的基本流程，以及阅读 <a href=\"https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md\">Raft 论文译文</a>来获取更加详细的信息。</p>\n<h2 id=\"领导选取\"><a href=\"#领导选取\" class=\"headerlink\" title=\"领导选取\"></a>领导选取</h2><p>Raft 的节点有三种状态：跟随者，候选人和领导者。</p>\n<p>一开始，每个节点都是跟随者，经过领导选举的流程，会产生一个领导者。在正常情况下，一个集群只有一个领导者，负责接收客户端消息以及日志同步，剩下的都是跟随者。</p>\n<p>当跟随者有一个选举时间没有收到来自领导者的消息后，就会把自己变成候选人，并给自己投票。这里还会额外记录这是第几次选举，也就是任期号。</p>\n<p>节点变成候选人之后，会给其他的机器发送竞选通知。在此期间，候选人节点会一直保持候选人状态，直到以下三种情况发生：</p>\n<ul>\n<li>候选人赢得选举成为领导者</li>\n</ul>\n<p>其他节点收到竞选通知之后，按照先来先服务的原则，如果自己还没有变成候选人且没有给其他的候选人节点投票过，就会投票给该候选人节点。如果该候选人节点得到了大多数的选票，就会变成领导者。</p>\n<ul>\n<li>其他候选人赢得选举成为领导者</li>\n</ul>\n<p>其他节点收到竞选通知之后，已经给其他的候选人节点投票了，就会忽视该候选人节点的通知。如果其他候选人节点得到了大多数的选票，那个候选人节点就会成为领导者，开始发送领导者同步消息。</p>\n<p>该候选人节点收到领导者同步消息，并且判断是当前或者更晚的任期选举出来的领导者，就知道已经有了其他的领导者，自动退出候选人状态成为跟随者。</p>\n<ul>\n<li>一段时间之后没有选出领导者</li>\n</ul>\n<p>这种情况一般出现在好几个候选人的情况下，导致所有候选人都没有得到大部分选票。在这种情况下，每一个候选人都会选举超时，之后会依据随机的选举超时时间，再次重复领导选举过程。由于随机的选举超时时间，下一轮选举中候选人出现的时间会有差别，这让这种情况很少发生。</p>\n<h2 id=\"日志复制\"><a href=\"#日志复制\" class=\"headerlink\" title=\"日志复制\"></a>日志复制</h2><p>领导者会按照一个时间定时给其他的机器发送心跳请求，其他机器收到后也会回复。这个时间需要远小于选举超时时间，避免在领导者正常工作的情况下，因为网络延迟等原因让跟随者收不到领导者的消息，错误认为当前集群没有领导者。</p>\n<p>当客户端请求的时候，领导者先更新自己本地的日志，然后把日志通过心跳请求复制给其他的机器，其他机器更新本地日志后，会在回复心跳的时候通知领导者。这里如果有机器没有回包，领导人即使向客户端回包了，也会无限重试，直到所有的跟随者都存储了日志。</p>\n<p>领导者收到大多数机器的更新之后，就会执行日志更新本地数据，通知客户端请求成功。下一次心跳，领导者会把 commit 请求发给其他机器。其他机器收到后，也会更新自己的本地数据。</p>\n<h2 id=\"安全性\"><a href=\"#安全性\" class=\"headerlink\" title=\"安全性\"></a>安全性</h2><h3 id=\"选举限制\"><a href=\"#选举限制\" class=\"headerlink\" title=\"选举限制\"></a>选举限制</h3><p>选举的时候会保证领导者一定有所有的日志。投票请求会包含当前机器最新的日志，如果跟随者发现候选人发来的投票请求中，日志没有自己新，那就会拒绝投票。</p>\n<p>基于这个原理，可以证明领导者一定拥有之前提交的日志信息。简单来说就是大多数机器都复制了才会提交，而提交之后大多数机器都有最新的日志，不会投票给没有日志的候选人。</p>\n<p>另外，服务器有当前领导者存在的时候，不会响应要求投票的请求，这保证了旧配置服务器被移除的时候它可能会进行选举过程的问题。</p>\n<h3 id=\"避免脑裂\"><a href=\"#避免脑裂\" class=\"headerlink\" title=\"避免脑裂\"></a>避免脑裂</h3><p>如果网络之间出现问题，例如 5 台机器，2 台机器和其他 3 台机器不通。</p>\n<p>这种情况下，这个集群会出现两个领导者。其中一个是原本的领导者，位于 2 台机器的集群；另一个是 3 台机器的集群新选举出来的。但是 2 台机器的小集群因为得不到大多数机器的更新确认信息，所以无法更新数据，而 3 台机器的集群则可以更新。</p>\n<p>当网络恢复后，2 台机器的集群收到 3 台机器集群的心跳请求，因为 3 台机器的集群的任期号更高，所以会采用 3 台机器集群的日志和数据，保证了集群整体还是一致的。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li><a href=\"https://thesecretlivesofdata.com/raft/\">Raft 动画</a></li>\n<li><a href=\"https://github.com/maemual/raft-zh_cn/blob/master/raft-zh_cn.md\">Raft 论文译文</a></li>\n</ul>\n","path":"2024/04/03/Raft算法基础介绍/","permalink":"https://xuh723.github.io/2024/04/03/Raft%E7%AE%97%E6%B3%95%E5%9F%BA%E7%A1%80%E4%BB%8B%E7%BB%8D/","tags":[{"name":"技术基础","_id":"clvj9j4ff0006r4w9f5hr9cqg","slug":"技术基础","path":"tags/技术基础/","permalink":"https://xuh723.github.io/tags/%E6%8A%80%E6%9C%AF%E5%9F%BA%E7%A1%80/","length":4},{"name":"分布式架构","_id":"clvj9j4fk000kr4w9cod3f33u","slug":"分布式架构","path":"tags/分布式架构/","permalink":"https://xuh723.github.io/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E6%9E%B6%E6%9E%84/","length":1}],"categories":[],"prev":{"title":"缓存模式和缓存问题介绍","date":"2024-04-05T16:27:14.000Z","slug":"缓存模式和缓存问题介绍","published":true,"updated":"2024-04-28T08:17:44.315Z","_id":"clvj9j4fa0003r4w9efis2dpp","layout":"post","photos":[],"excerpt":"","path":"2024/04/06/缓存模式和缓存问题介绍/","permalink":"https://xuh723.github.io/2024/04/06/%E7%BC%93%E5%AD%98%E6%A8%A1%E5%BC%8F%E5%92%8C%E7%BC%93%E5%AD%98%E9%97%AE%E9%A2%98%E4%BB%8B%E7%BB%8D/","__post":true},"next":{"title":"Kafka消息队列简单介绍","date":"2024-03-30T11:29:14.000Z","slug":"Kafka消息队列简单介绍","published":true,"updated":"2024-04-28T08:14:46.217Z","_id":"clvj9j4fc0004r4w94xgs39fs","layout":"post","photos":[],"excerpt":"","path":"2024/03/30/Kafka消息队列简单介绍/","permalink":"https://xuh723.github.io/2024/03/30/Kafka%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D/","__post":true},"__post":true}