{"title":"groupcache简单介绍","date":"2024-04-28T08:15:32.000Z","toc":true,"source":"_posts/2024-04-28-groupcache简单介绍.md","raw":"---\ntitle: groupcache简单介绍\ndate: 2024-04-28 16:15:32\ntags: [组件分析, 数据存储]\ntoc: true\n---\n\n## 简单介绍\n\n### 基本介绍\n\ngroupcache 是一个 Go 语言的分布式的缓存库，主要特点是支持分布式集群的部署方式。传统的 Memcached 的数据是缓存在单个实例中的，每个实例都有自己的一套缓存，而 groupcache 中，同一个集群中，访问任何一个实例都可以得到数据。\n\ngroupcache 最显著的特征是只用于存储静态资源，资源在缓存中不支持修改。groupcache 缓存库中不提供 update 和 delete 等方法，只有 get 一种方法。\n\ngroupcache 在获取缓存数据的时候，首先从本机缓存和本次存储的热点缓存中获取。如果获取失败，会通过 http 调用去查询 peer 机器上的缓存，如果还是没有，才去底层数据存储中获取。在获取数据的过程中，groupcache 会通过 singleflight 来保证相同的请求只访问一次数据库。\n\n### 对比 Memcached\n\n文档中介绍了的 groupcache 相比 memcached 的区别：\n\n- 不需要运行单独的服务，以库调用的方式给客户端使用\n- 自带缓存填充机制，缓存未命中时只有一个进程会去加载并填充数据\n- 不支持版本化数据，存储的数据不可更改，没有过期时间和淘汰机制等\n- 这也意味着 groupcache 支持热点数据的镜像存储，避免了热点负载问题\n- 目前仅能用于 Go 语言\n\n## 基本流程\n\n### 名词解释\n\n- group\n\n缓存的主要结构体，在最开始创建缓存的时候会指定 group 和名称。\n\n- peer\n\n存储数据的节点，是通过一致性哈希来决定 key 对应的数据存储在哪个 peer 节点上的。\n\n- mainCache\n\npeer 节点本地的缓存。\n\n- hotCache\n\n节点本地的热点数据缓存，在查询数据后有十分之一的概率把数据作为热点数据存在本地。这样做的好处是真正的热点数据会有高概率存储在各个 peer 节点上。\n\n### 请求流程\n\n1. 用户发起请求到 httppool 的监听节点，该监听节点本身也相当于一个 peer 节点\n2. 分析请求，根据 groupname 调用相应的 group\n3. 查询本地 mainCache 和 hotCache，找到数据就返回\n4. 没有找到数据，查询当前 peer 节点是否是当前请求对应的 peer 节点\n5. 是的话就从本地数据集获取数据，存放在 mainCache 缓存中\n6. 否则就从远程对应的 peer 节点获取数据，获取后有 1/10 的概率存储在 hotCache 中\n7. 返回数据\n\n## 组件分析\n\n### group\n\nGroup 是缓存的主要结构体，包含了获取缓存的完整流程，它的结构体字段如下所示。\n\n```Go\ntype Group struct {\n\tname       string\n\tgetter     Getter\n\tpeersOnce  sync.Once\n\tpeers      PeerPicker\n\tcacheBytes int64 // limit for sum of mainCache and hotCache size\n\n\t// mainCache is a cache of the keys for which this process\n\t// (amongst its peers) is authoritative. That is, this cache\n\t// contains keys which consistent hash on to this process's\n\t// peer number.\n\tmainCache cache\n\n\t// hotCache contains keys/values for which this peer is not\n\t// authoritative (otherwise they would be in mainCache), but\n\t// are popular enough to warrant mirroring in this process to\n\t// avoid going over the network to fetch from a peer.  Having\n\t// a hotCache avoids network hotspotting, where a peer's\n\t// network card could become the bottleneck on a popular key.\n\t// This cache is used sparingly to maximize the total number\n\t// of key/value pairs that can be stored globally.\n\thotCache cache\n\n\t// loadGroup ensures that each key is only fetched once\n\t// (either locally or remotely), regardless of the number of\n\t// concurrent callers.\n\tloadGroup flightGroup\n\n\t_ int32 // force Stats to be 8-byte aligned on 32-bit platforms\n\n\t// Stats are statistics on the group.\n\tStats Stats\n}\n```\n\n可以看到，Group 中包含了本地缓存的完整内容，核心是 Get 方法。\n\n1. 首先查询本地的 mainCache 和 hotCache，获取 key 对应的数据值，查询到就直接返回\n2. 如果不存在，就通过 PickPeer 方法，查询 key 对应的节点，发起 http 请求从对应的节点获取数据\n3. 如果 key 对应的节点就是本地，那就调用用户定义的 Getter 方法，获取原始数据\n\n### consistenthash\n\ngroupcache 通过一致性哈希的方式来分配 key 存储的节点。一致性哈希提供的好处是，当节点数量出现变化，例如节点宕机或者新节点加入的时候，整体 key 和节点的映射关系不会出现大的变化。\n\n### singleflight\n\nsingleflight 的功能是当多个并发请求同时请求相同的 key 的时候，保证函数只调用一次。singleflight 本身也是常见的缓存击穿的问题的解决方案，可以避免大量同样的请求到底层数据库，起到对数据库的保护作用。\n\nsingleflight 的实现原理是在调用请求的时候手动分配一个 key。在请求调用之前，会先查询这个 key 对应的请求是否已经存在了，如果还不存在，就 new 一个 key 对应的请求；如果已经存在，就进入等待流程。当请求调用函数获取到数据之后，会通知所有在等待的请求，操作完成，并在 map 中删除这个 key。其他在等待的请求收到通知后会获取数据并返回。\n\n实际使用中，考虑到调用底层的查询可能出错或者超时，一般还要分配一个超时时间或者主动让 key 对应的请求失效，这里暂时不讨论 singleflight 的实现细节。\n\n### lru\n\nLRU 算法（最近最少使用）是比较常用的缓存更新算法。groupcache 使用的 LRU 算法并没有特殊的优化，将最新用到的数据放到链表的头部，淘汰的时候从链表尾部开始淘汰。\n\n这种常规 LRU 算法的问题是如果出现扫描式大量数据被访问的时候，会导致整个缓存的数据都被淘汰，如果后续这些数据不再被用到，会导致缓存命中率大大降低。其他一些应用，例如 MySQL 通过把 LRU 的链表分成 old 和 young 两部分来缓解这个问题。\n\n### httppool\n\nhttppool 封装了和各个节点的通信过程，并保存了所有远端节点的通信地址。当 groupcache 需要向其他节点发起 http 请求获取数据的时候，就会通过 httppool 调用对应节点的提供的 httpGetter 方法，从指定的服务器节点获取数据。\n\n## 参考资料\n\n- [groupcache 官方文档](https://pkg.go.dev/github.com/golang/groupcache#section-readme)\n- [groupcache github 地址](https://github.com/golang/groupcache)\n","slug":"groupcache简单介绍","published":true,"updated":"2024-04-28T08:20:18.535Z","_id":"clxsp136e0009igw98kcv0930","comments":true,"layout":"post","photos":[],"html":"<h2 id=\"简单介绍\"><a href=\"#简单介绍\" class=\"headerlink\" title=\"简单介绍\"></a>简单介绍</h2><h3 id=\"基本介绍\"><a href=\"#基本介绍\" class=\"headerlink\" title=\"基本介绍\"></a>基本介绍</h3><p>groupcache 是一个 Go 语言的分布式的缓存库，主要特点是支持分布式集群的部署方式。传统的 Memcached 的数据是缓存在单个实例中的，每个实例都有自己的一套缓存，而 groupcache 中，同一个集群中，访问任何一个实例都可以得到数据。</p>\n<p>groupcache 最显著的特征是只用于存储静态资源，资源在缓存中不支持修改。groupcache 缓存库中不提供 update 和 delete 等方法，只有 get 一种方法。</p>\n<p>groupcache 在获取缓存数据的时候，首先从本机缓存和本次存储的热点缓存中获取。如果获取失败，会通过 http 调用去查询 peer 机器上的缓存，如果还是没有，才去底层数据存储中获取。在获取数据的过程中，groupcache 会通过 singleflight 来保证相同的请求只访问一次数据库。</p>\n<h3 id=\"对比-Memcached\"><a href=\"#对比-Memcached\" class=\"headerlink\" title=\"对比 Memcached\"></a>对比 Memcached</h3><p>文档中介绍了的 groupcache 相比 memcached 的区别：</p>\n<ul>\n<li>不需要运行单独的服务，以库调用的方式给客户端使用</li>\n<li>自带缓存填充机制，缓存未命中时只有一个进程会去加载并填充数据</li>\n<li>不支持版本化数据，存储的数据不可更改，没有过期时间和淘汰机制等</li>\n<li>这也意味着 groupcache 支持热点数据的镜像存储，避免了热点负载问题</li>\n<li>目前仅能用于 Go 语言</li>\n</ul>\n<h2 id=\"基本流程\"><a href=\"#基本流程\" class=\"headerlink\" title=\"基本流程\"></a>基本流程</h2><h3 id=\"名词解释\"><a href=\"#名词解释\" class=\"headerlink\" title=\"名词解释\"></a>名词解释</h3><ul>\n<li>group</li>\n</ul>\n<p>缓存的主要结构体，在最开始创建缓存的时候会指定 group 和名称。</p>\n<ul>\n<li>peer</li>\n</ul>\n<p>存储数据的节点，是通过一致性哈希来决定 key 对应的数据存储在哪个 peer 节点上的。</p>\n<ul>\n<li>mainCache</li>\n</ul>\n<p>peer 节点本地的缓存。</p>\n<ul>\n<li>hotCache</li>\n</ul>\n<p>节点本地的热点数据缓存，在查询数据后有十分之一的概率把数据作为热点数据存在本地。这样做的好处是真正的热点数据会有高概率存储在各个 peer 节点上。</p>\n<h3 id=\"请求流程\"><a href=\"#请求流程\" class=\"headerlink\" title=\"请求流程\"></a>请求流程</h3><ol>\n<li>用户发起请求到 httppool 的监听节点，该监听节点本身也相当于一个 peer 节点</li>\n<li>分析请求，根据 groupname 调用相应的 group</li>\n<li>查询本地 mainCache 和 hotCache，找到数据就返回</li>\n<li>没有找到数据，查询当前 peer 节点是否是当前请求对应的 peer 节点</li>\n<li>是的话就从本地数据集获取数据，存放在 mainCache 缓存中</li>\n<li>否则就从远程对应的 peer 节点获取数据，获取后有 1&#x2F;10 的概率存储在 hotCache 中</li>\n<li>返回数据</li>\n</ol>\n<h2 id=\"组件分析\"><a href=\"#组件分析\" class=\"headerlink\" title=\"组件分析\"></a>组件分析</h2><h3 id=\"group\"><a href=\"#group\" class=\"headerlink\" title=\"group\"></a>group</h3><p>Group 是缓存的主要结构体，包含了获取缓存的完整流程，它的结构体字段如下所示。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> Group <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">\tname       <span class=\"type\">string</span></span><br><span class=\"line\">\tgetter     Getter</span><br><span class=\"line\">\tpeersOnce  sync.Once</span><br><span class=\"line\">\tpeers      PeerPicker</span><br><span class=\"line\">\tcacheBytes <span class=\"type\">int64</span> <span class=\"comment\">// limit for sum of mainCache and hotCache size</span></span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// mainCache is a cache of the keys for which this process</span></span><br><span class=\"line\">\t<span class=\"comment\">// (amongst its peers) is authoritative. That is, this cache</span></span><br><span class=\"line\">\t<span class=\"comment\">// contains keys which consistent hash on to this process&#x27;s</span></span><br><span class=\"line\">\t<span class=\"comment\">// peer number.</span></span><br><span class=\"line\">\tmainCache cache</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// hotCache contains keys/values for which this peer is not</span></span><br><span class=\"line\">\t<span class=\"comment\">// authoritative (otherwise they would be in mainCache), but</span></span><br><span class=\"line\">\t<span class=\"comment\">// are popular enough to warrant mirroring in this process to</span></span><br><span class=\"line\">\t<span class=\"comment\">// avoid going over the network to fetch from a peer.  Having</span></span><br><span class=\"line\">\t<span class=\"comment\">// a hotCache avoids network hotspotting, where a peer&#x27;s</span></span><br><span class=\"line\">\t<span class=\"comment\">// network card could become the bottleneck on a popular key.</span></span><br><span class=\"line\">\t<span class=\"comment\">// This cache is used sparingly to maximize the total number</span></span><br><span class=\"line\">\t<span class=\"comment\">// of key/value pairs that can be stored globally.</span></span><br><span class=\"line\">\thotCache cache</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// loadGroup ensures that each key is only fetched once</span></span><br><span class=\"line\">\t<span class=\"comment\">// (either locally or remotely), regardless of the number of</span></span><br><span class=\"line\">\t<span class=\"comment\">// concurrent callers.</span></span><br><span class=\"line\">\tloadGroup flightGroup</span><br><span class=\"line\"></span><br><span class=\"line\">\t_ <span class=\"type\">int32</span> <span class=\"comment\">// force Stats to be 8-byte aligned on 32-bit platforms</span></span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// Stats are statistics on the group.</span></span><br><span class=\"line\">\tStats Stats</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>可以看到，Group 中包含了本地缓存的完整内容，核心是 Get 方法。</p>\n<ol>\n<li>首先查询本地的 mainCache 和 hotCache，获取 key 对应的数据值，查询到就直接返回</li>\n<li>如果不存在，就通过 PickPeer 方法，查询 key 对应的节点，发起 http 请求从对应的节点获取数据</li>\n<li>如果 key 对应的节点就是本地，那就调用用户定义的 Getter 方法，获取原始数据</li>\n</ol>\n<h3 id=\"consistenthash\"><a href=\"#consistenthash\" class=\"headerlink\" title=\"consistenthash\"></a>consistenthash</h3><p>groupcache 通过一致性哈希的方式来分配 key 存储的节点。一致性哈希提供的好处是，当节点数量出现变化，例如节点宕机或者新节点加入的时候，整体 key 和节点的映射关系不会出现大的变化。</p>\n<h3 id=\"singleflight\"><a href=\"#singleflight\" class=\"headerlink\" title=\"singleflight\"></a>singleflight</h3><p>singleflight 的功能是当多个并发请求同时请求相同的 key 的时候，保证函数只调用一次。singleflight 本身也是常见的缓存击穿的问题的解决方案，可以避免大量同样的请求到底层数据库，起到对数据库的保护作用。</p>\n<p>singleflight 的实现原理是在调用请求的时候手动分配一个 key。在请求调用之前，会先查询这个 key 对应的请求是否已经存在了，如果还不存在，就 new 一个 key 对应的请求；如果已经存在，就进入等待流程。当请求调用函数获取到数据之后，会通知所有在等待的请求，操作完成，并在 map 中删除这个 key。其他在等待的请求收到通知后会获取数据并返回。</p>\n<p>实际使用中，考虑到调用底层的查询可能出错或者超时，一般还要分配一个超时时间或者主动让 key 对应的请求失效，这里暂时不讨论 singleflight 的实现细节。</p>\n<h3 id=\"lru\"><a href=\"#lru\" class=\"headerlink\" title=\"lru\"></a>lru</h3><p>LRU 算法（最近最少使用）是比较常用的缓存更新算法。groupcache 使用的 LRU 算法并没有特殊的优化，将最新用到的数据放到链表的头部，淘汰的时候从链表尾部开始淘汰。</p>\n<p>这种常规 LRU 算法的问题是如果出现扫描式大量数据被访问的时候，会导致整个缓存的数据都被淘汰，如果后续这些数据不再被用到，会导致缓存命中率大大降低。其他一些应用，例如 MySQL 通过把 LRU 的链表分成 old 和 young 两部分来缓解这个问题。</p>\n<h3 id=\"httppool\"><a href=\"#httppool\" class=\"headerlink\" title=\"httppool\"></a>httppool</h3><p>httppool 封装了和各个节点的通信过程，并保存了所有远端节点的通信地址。当 groupcache 需要向其他节点发起 http 请求获取数据的时候，就会通过 httppool 调用对应节点的提供的 httpGetter 方法，从指定的服务器节点获取数据。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li><a href=\"https://pkg.go.dev/github.com/golang/groupcache#section-readme\">groupcache 官方文档</a></li>\n<li><a href=\"https://github.com/golang/groupcache\">groupcache github 地址</a></li>\n</ul>\n","excerpt":"","more":"<h2 id=\"简单介绍\"><a href=\"#简单介绍\" class=\"headerlink\" title=\"简单介绍\"></a>简单介绍</h2><h3 id=\"基本介绍\"><a href=\"#基本介绍\" class=\"headerlink\" title=\"基本介绍\"></a>基本介绍</h3><p>groupcache 是一个 Go 语言的分布式的缓存库，主要特点是支持分布式集群的部署方式。传统的 Memcached 的数据是缓存在单个实例中的，每个实例都有自己的一套缓存，而 groupcache 中，同一个集群中，访问任何一个实例都可以得到数据。</p>\n<p>groupcache 最显著的特征是只用于存储静态资源，资源在缓存中不支持修改。groupcache 缓存库中不提供 update 和 delete 等方法，只有 get 一种方法。</p>\n<p>groupcache 在获取缓存数据的时候，首先从本机缓存和本次存储的热点缓存中获取。如果获取失败，会通过 http 调用去查询 peer 机器上的缓存，如果还是没有，才去底层数据存储中获取。在获取数据的过程中，groupcache 会通过 singleflight 来保证相同的请求只访问一次数据库。</p>\n<h3 id=\"对比-Memcached\"><a href=\"#对比-Memcached\" class=\"headerlink\" title=\"对比 Memcached\"></a>对比 Memcached</h3><p>文档中介绍了的 groupcache 相比 memcached 的区别：</p>\n<ul>\n<li>不需要运行单独的服务，以库调用的方式给客户端使用</li>\n<li>自带缓存填充机制，缓存未命中时只有一个进程会去加载并填充数据</li>\n<li>不支持版本化数据，存储的数据不可更改，没有过期时间和淘汰机制等</li>\n<li>这也意味着 groupcache 支持热点数据的镜像存储，避免了热点负载问题</li>\n<li>目前仅能用于 Go 语言</li>\n</ul>\n<h2 id=\"基本流程\"><a href=\"#基本流程\" class=\"headerlink\" title=\"基本流程\"></a>基本流程</h2><h3 id=\"名词解释\"><a href=\"#名词解释\" class=\"headerlink\" title=\"名词解释\"></a>名词解释</h3><ul>\n<li>group</li>\n</ul>\n<p>缓存的主要结构体，在最开始创建缓存的时候会指定 group 和名称。</p>\n<ul>\n<li>peer</li>\n</ul>\n<p>存储数据的节点，是通过一致性哈希来决定 key 对应的数据存储在哪个 peer 节点上的。</p>\n<ul>\n<li>mainCache</li>\n</ul>\n<p>peer 节点本地的缓存。</p>\n<ul>\n<li>hotCache</li>\n</ul>\n<p>节点本地的热点数据缓存，在查询数据后有十分之一的概率把数据作为热点数据存在本地。这样做的好处是真正的热点数据会有高概率存储在各个 peer 节点上。</p>\n<h3 id=\"请求流程\"><a href=\"#请求流程\" class=\"headerlink\" title=\"请求流程\"></a>请求流程</h3><ol>\n<li>用户发起请求到 httppool 的监听节点，该监听节点本身也相当于一个 peer 节点</li>\n<li>分析请求，根据 groupname 调用相应的 group</li>\n<li>查询本地 mainCache 和 hotCache，找到数据就返回</li>\n<li>没有找到数据，查询当前 peer 节点是否是当前请求对应的 peer 节点</li>\n<li>是的话就从本地数据集获取数据，存放在 mainCache 缓存中</li>\n<li>否则就从远程对应的 peer 节点获取数据，获取后有 1&#x2F;10 的概率存储在 hotCache 中</li>\n<li>返回数据</li>\n</ol>\n<h2 id=\"组件分析\"><a href=\"#组件分析\" class=\"headerlink\" title=\"组件分析\"></a>组件分析</h2><h3 id=\"group\"><a href=\"#group\" class=\"headerlink\" title=\"group\"></a>group</h3><p>Group 是缓存的主要结构体，包含了获取缓存的完整流程，它的结构体字段如下所示。</p>\n<figure class=\"highlight go\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">type</span> Group <span class=\"keyword\">struct</span> &#123;</span><br><span class=\"line\">\tname       <span class=\"type\">string</span></span><br><span class=\"line\">\tgetter     Getter</span><br><span class=\"line\">\tpeersOnce  sync.Once</span><br><span class=\"line\">\tpeers      PeerPicker</span><br><span class=\"line\">\tcacheBytes <span class=\"type\">int64</span> <span class=\"comment\">// limit for sum of mainCache and hotCache size</span></span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// mainCache is a cache of the keys for which this process</span></span><br><span class=\"line\">\t<span class=\"comment\">// (amongst its peers) is authoritative. That is, this cache</span></span><br><span class=\"line\">\t<span class=\"comment\">// contains keys which consistent hash on to this process&#x27;s</span></span><br><span class=\"line\">\t<span class=\"comment\">// peer number.</span></span><br><span class=\"line\">\tmainCache cache</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// hotCache contains keys/values for which this peer is not</span></span><br><span class=\"line\">\t<span class=\"comment\">// authoritative (otherwise they would be in mainCache), but</span></span><br><span class=\"line\">\t<span class=\"comment\">// are popular enough to warrant mirroring in this process to</span></span><br><span class=\"line\">\t<span class=\"comment\">// avoid going over the network to fetch from a peer.  Having</span></span><br><span class=\"line\">\t<span class=\"comment\">// a hotCache avoids network hotspotting, where a peer&#x27;s</span></span><br><span class=\"line\">\t<span class=\"comment\">// network card could become the bottleneck on a popular key.</span></span><br><span class=\"line\">\t<span class=\"comment\">// This cache is used sparingly to maximize the total number</span></span><br><span class=\"line\">\t<span class=\"comment\">// of key/value pairs that can be stored globally.</span></span><br><span class=\"line\">\thotCache cache</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// loadGroup ensures that each key is only fetched once</span></span><br><span class=\"line\">\t<span class=\"comment\">// (either locally or remotely), regardless of the number of</span></span><br><span class=\"line\">\t<span class=\"comment\">// concurrent callers.</span></span><br><span class=\"line\">\tloadGroup flightGroup</span><br><span class=\"line\"></span><br><span class=\"line\">\t_ <span class=\"type\">int32</span> <span class=\"comment\">// force Stats to be 8-byte aligned on 32-bit platforms</span></span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// Stats are statistics on the group.</span></span><br><span class=\"line\">\tStats Stats</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n\n<p>可以看到，Group 中包含了本地缓存的完整内容，核心是 Get 方法。</p>\n<ol>\n<li>首先查询本地的 mainCache 和 hotCache，获取 key 对应的数据值，查询到就直接返回</li>\n<li>如果不存在，就通过 PickPeer 方法，查询 key 对应的节点，发起 http 请求从对应的节点获取数据</li>\n<li>如果 key 对应的节点就是本地，那就调用用户定义的 Getter 方法，获取原始数据</li>\n</ol>\n<h3 id=\"consistenthash\"><a href=\"#consistenthash\" class=\"headerlink\" title=\"consistenthash\"></a>consistenthash</h3><p>groupcache 通过一致性哈希的方式来分配 key 存储的节点。一致性哈希提供的好处是，当节点数量出现变化，例如节点宕机或者新节点加入的时候，整体 key 和节点的映射关系不会出现大的变化。</p>\n<h3 id=\"singleflight\"><a href=\"#singleflight\" class=\"headerlink\" title=\"singleflight\"></a>singleflight</h3><p>singleflight 的功能是当多个并发请求同时请求相同的 key 的时候，保证函数只调用一次。singleflight 本身也是常见的缓存击穿的问题的解决方案，可以避免大量同样的请求到底层数据库，起到对数据库的保护作用。</p>\n<p>singleflight 的实现原理是在调用请求的时候手动分配一个 key。在请求调用之前，会先查询这个 key 对应的请求是否已经存在了，如果还不存在，就 new 一个 key 对应的请求；如果已经存在，就进入等待流程。当请求调用函数获取到数据之后，会通知所有在等待的请求，操作完成，并在 map 中删除这个 key。其他在等待的请求收到通知后会获取数据并返回。</p>\n<p>实际使用中，考虑到调用底层的查询可能出错或者超时，一般还要分配一个超时时间或者主动让 key 对应的请求失效，这里暂时不讨论 singleflight 的实现细节。</p>\n<h3 id=\"lru\"><a href=\"#lru\" class=\"headerlink\" title=\"lru\"></a>lru</h3><p>LRU 算法（最近最少使用）是比较常用的缓存更新算法。groupcache 使用的 LRU 算法并没有特殊的优化，将最新用到的数据放到链表的头部，淘汰的时候从链表尾部开始淘汰。</p>\n<p>这种常规 LRU 算法的问题是如果出现扫描式大量数据被访问的时候，会导致整个缓存的数据都被淘汰，如果后续这些数据不再被用到，会导致缓存命中率大大降低。其他一些应用，例如 MySQL 通过把 LRU 的链表分成 old 和 young 两部分来缓解这个问题。</p>\n<h3 id=\"httppool\"><a href=\"#httppool\" class=\"headerlink\" title=\"httppool\"></a>httppool</h3><p>httppool 封装了和各个节点的通信过程，并保存了所有远端节点的通信地址。当 groupcache 需要向其他节点发起 http 请求获取数据的时候，就会通过 httppool 调用对应节点的提供的 httpGetter 方法，从指定的服务器节点获取数据。</p>\n<h2 id=\"参考资料\"><a href=\"#参考资料\" class=\"headerlink\" title=\"参考资料\"></a>参考资料</h2><ul>\n<li><a href=\"https://pkg.go.dev/github.com/golang/groupcache#section-readme\">groupcache 官方文档</a></li>\n<li><a href=\"https://github.com/golang/groupcache\">groupcache github 地址</a></li>\n</ul>\n","path":"2024/04/28/groupcache简单介绍/","permalink":"https://xuh723.github.io/2024/04/28/groupcache%E7%AE%80%E5%8D%95%E4%BB%8B%E7%BB%8D/","tags":[{"name":"数据存储","_id":"clxsp136i000figw92ve75x23","slug":"数据存储","path":"tags/数据存储/","permalink":"https://xuh723.github.io/tags/%E6%95%B0%E6%8D%AE%E5%AD%98%E5%82%A8/","length":3},{"name":"组件分析","_id":"clxsp136k000rigw900km7dij","slug":"组件分析","path":"tags/组件分析/","permalink":"https://xuh723.github.io/tags/%E7%BB%84%E4%BB%B6%E5%88%86%E6%9E%90/","length":2}],"categories":[],"prev":{"title":"最短路算法小结","date":"2024-05-05T05:13:08.000Z","slug":"最短路算法小结","published":true,"updated":"2024-06-24T07:55:10.853Z","_id":"clxsp136e0008igw9akagfbct","layout":"post","photos":[],"excerpt":"","path":"2024/05/05/最短路算法小结/","permalink":"https://xuh723.github.io/2024/05/05/%E6%9C%80%E7%9F%AD%E8%B7%AF%E7%AE%97%E6%B3%95%E5%B0%8F%E7%BB%93/","__post":true},"next":{"title":"缓存模式和缓存问题介绍","date":"2024-04-05T16:27:14.000Z","slug":"缓存模式和缓存问题介绍","published":true,"updated":"2024-04-28T08:17:44.315Z","_id":"clxsp136c0005igw91xvm1y80","layout":"post","photos":[],"excerpt":"","path":"2024/04/06/缓存模式和缓存问题介绍/","permalink":"https://xuh723.github.io/2024/04/06/%E7%BC%93%E5%AD%98%E6%A8%A1%E5%BC%8F%E5%92%8C%E7%BC%93%E5%AD%98%E9%97%AE%E9%A2%98%E4%BB%8B%E7%BB%8D/","__post":true},"__post":true}